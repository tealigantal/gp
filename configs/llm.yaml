provider: deepseek
base_url: "http://llm-proxy:8080/v1"
model: "deepseek-chat"
api_key_env: "DEEPSEEK_API_KEY"
temperature: 0
max_tokens: 1200
timeout_sec: 60
retries: 2
json_mode: true
